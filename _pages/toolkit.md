---
layout: archive
title: "üõ†Ô∏è My Tech Arsenal"
permalink: /toolkit/
author_profile: true
---

<!-- {% include base_path %}


{% for post in site.portfolio %}
  {% include archive-single.html %}
{% endfor %} -->



- **Languages:** *Java, Python, C/C++, Scala, JavaScript*  
  The **core trio** that I wield across projects, each with its unique superpowers. Whether it‚Äôs Python's adaptability, Java's robustness, or JavaScript‚Äôs interactivity, these languages are my go-to tools for crafting efficient solutions.

- **Frameworks & Libraries:** *ReactJS, Spring Boot(MicroServices, SpringAI), Spark, Kafka*  
  From powering responsive UIs with **ReactJS** to building resilient backend services with **Spring Boot**, these are the engines that bring my ideas to life. **Spark** and **Kafka** fuel my data processing workflows, ensuring seamless streaming and analysis at scale.

- **Databases:** *MySQL, Snowflake, MongoDB, PostgreSQL*  
  Databases are where the magic of data happens. **MySQL** for reliable relational storage, **MongoDB** for flexible NoSQL solutions, and **PostgreSQL** for complex queries effortlessly, and **Snowflake** takes data warehousing and analytics to the next level with its cloud-native architecture ‚Äì they‚Äôre the vaults where I manage and safeguard data treasures.

- **Cloud Platforms:** *AWS, Azure, Google Cloud, Databricks*  
  My applications take flight on the **cloud stage**, with **AWS**, **Azure**, and **Google Cloud** enabling scalability and reliability. **Databricks** powers my big data and machine learning workflows, transforming raw data into actionable insights.

- **AI/ML & Data Science:** *Pandas, NumPy, scikit-learn, logistic regression, random forest, gradient boosting, neural networks etc.*
  Building, training, and evaluating models‚Äîfrom classical algorithms to advanced deep-learning architectures.

- **DevOps & Data Tools:** *Git, Docker, Kubernetes, Airflow*  
  Keeping projects streamlined and scalable requires the right tools. **Git** for version control, **Docker** and **Kubernetes** for containerization and orchestration, and **Apache Airflow** for automating complex data pipelines. These tools ensure every project is efficient, reproducible, and ready to grow.


